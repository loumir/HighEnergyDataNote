\documentclass[11pt,a4paper]{ivoa}
\input tthdefs

\title{Virtual Observatory and High Energy Astrophysics}

% see draft note here:

% see ivoatexDoc for what group names to use here; use \ivoagroup[IG] for
% interest groups.
\ivoagroup{DM}

\author{HE club}

\editor{Mathieu Servillat}

% \previousversion[????URL????]{????Concise Document Label????}
\previousversion{This is the first public release}

\usepackage{longtable}
%\usepackage{booktabs} % For prettier tables
\usepackage{lscape}
%\usepackage{minted}

\setlength {\marginparwidth }{2cm}
\usepackage{todonotes}

\begin{document}

\begin{abstract}
Virtual Observatory and High Energy Astrophysics
\end{abstract}


\section*{Acknowledgments}

We acknowledge support from the ESCAPE project funded by the EU Horizon 2020 research and innovation program (Grant Agreement n.824064). Additional funding was provided by the INSU (Action Sp\'ecifique Observatoire Virtuel, ASOV), the Action F\'ed\'eratrice CTA at the Observatoire de Paris and the Paris Astronomical Data Centre (PADC).

\section*{Conformance-related definitions}

The words ``MUST'', ``SHALL'', ``SHOULD'', ``MAY'', ``RECOMMENDED'', and
``OPTIONAL'' (in upper or lower case) used in this document are to be
interpreted as described in IETF standard RFC2119 \citep{std:RFC2119}.

The \emph{Virtual Observatory (VO)} is a
general term for a collection of federated resources that can be used
to conduct astronomical research, education, and outreach.
The \href{https://www.ivoa.net}{International
Virtual Observatory Alliance (IVOA)} is a global
collaboration of separately funded projects to develop standards and
infrastructure that enable VO applications.


\section{Introduction}

% We should introduce the purpose of the note in distribution and access of event list data products. Science cases should be focused to highlight that.

High Energy (HE) astronomy typically includes X-ray astronomy, gamma-ray astronomy, neutrino astronomy, studies of cosmic rays, and more recently gravitational wave astronomy. This domain is now sufficiently developed to provide high level data such as catalogs, images, including full-sky surveys for some missions, and sources properties in the shape of spectra and time series.
Such high level, HE observations have been included in the VO, via data access endpoints provided by observatories or by agencies and indexed in the VO Registry.
%Some high-energy (HE) data is already available via the VO. Images, time series, and spectra may be described with Obscore and access.

However, after browsing this data, users may want to download lower level data and reapply data reduction steps relevant to their Science objectives. A common scenario is to download HE "event" lists, i.e. lists of detected events on a HE detector, that are expected to be detection of particles (e.g. a HE photon), and the corresponding calibration files, including instrument response functions. The findability and accessibility of these data via the VO is the focus of this note.

We first report typical use cases for data access and analysis of data from current HE observatories. From those use cases, we note that some existing IVOA Recommendations are of interest to the domain. They should be further explored by HE observatories. We then discuss how standards could evolve to better integrate specific aspects of HE data, and if new standards should be developed.


% \subsection{Role within the VO Architecture}

% \begin{figure}
% \centering

% % As of ivoatex 1.2, the architecture diagram is generated by ivoatex in
% % SVG; copy ivoatex/archdiag-full.xml to role_diagram.xml and throw out
% % all lines not relevant to your standard.
% % Notes don't generally need this.  If you don't copy role_diagram.xml,
% % you must remove role_diagram.pdf from SOURCES in the Makefile.

% \includegraphics[width=0.9\textwidth]{role_diagram.pdf}
% \caption{Architecture diagram for this document}
% \label{fig:archdiag}
% \end{figure}

% Fig.~\ref{fig:archdiag} shows the role this document plays within the
% IVOA architecture \citep{2010ivoa.rept.1123A}.


\section{High Energy observatories and experiments}
%XMM use case scenario
%Données attachées ? data link?

There are various observatories, either from ground- or space-based, that distribute high-energy data with different level of involvement in the VO. We list here the observatories currently represented in the VO HE group. There are also other observatories that are connected to the VO in some way, and may join the group discussions at IVOA.


\subsection{Gamma-ray programs}

\subsubsection{CTAO}

The Cherenkov Telescope Array Observatory (CTAO) is the next generation ground-based instrument for gamma-ray astronomy at Very-High Energies (VHE). With 64 telescopes located in the northern and southern hemispheres, the CTAO will be the first open ground-based gamma-ray observatory and the world’s largest and most sensitive instrument to study high-energy phenomena in the Universe.
Building on the technology of current generation ground-based gamma-ray detectors (H.E.S.S., MAGIC and VERITAS), the CTAO will be between five and 10 times more sensitive and have unprecedented accuracy in its detection of high-energy gamma rays.

CTAO will distribute data as an open observatory, for the first time in this domain, with calls for proposals and publicly released data after a proprietary period. CTAO will ensure that the data provided will be FAIR: Findable, Accessible, Interoperable and Reusable, by following the FAIR Principles for data management \citep{Wilkinson2016}. In particular, because of the complex data processing and reconstruction step, the provision of provenance metadata for CTAO data has been a driver for the development of a provenance standard in Astronomy.

CTAO will also ensure VO compatibility of the distributed data and access systems. CTAO participated to the ESCAPE European Project, and is now part of the ESCAPE Open Collaboration to face common challenges for Research Infrastructure in the context of cloud computing, including data analysis and distribution.

A focus of CTAO is to distribute in this context their Data Level 3 (DL3) datasets, that correspond to lists of Cherenkov events detected by the telescopes along with the proper IRFs. CTAO is planning an internal and a public Science Data Challenge, which represent opportunities to build "VO inside" solutions.

\subsubsection{H.E.S.S}
\label{sec:hess}

H.E.S.S. is a system of Imaging Atmospheric Cherenkov Telescopes located in Namibia that investigates cosmic gamma rays in the energy range from 10s of GeV to 10s of TeV. It is constituted of four telescopes officially inaugurated in 2004, and a much larger fifth telescope operational since 2012, extending the energy coverage towards lower energies and further improving sensitivity.

The H.E.S.S. collaboration operates the telescopes as a private experiment and published mainly high level data, i.e. images, time series and spectra in scientific publications after dedicated analyses.

In September 2018, the H.E.S.S. Collaboration has, for the first time and unique time, released a small subset of its archival data in Flexible Image Transport System (FITS) format, an open file format widely used in astronomy. The release consists of event-lists and instrument response functions for observations of various well-known gamma-ray sources
\citep{hess-zenodo.1421098}.

This test data collection has been registered in the VO via a TAP service hosted at the Observatoire de Paris, with a tentative ObsCore description of each dataset. We hope that in the future, the H.E.S.S. legacy archive will be published in a similar way and accessible through the VO.



\subsection{X-ray programs}

\subsubsection{Chandra}

The Chandra X-ray Observatory, launched in 1999, is part of NASA's ﬂeet of "Great Observatories". Chandra allows scientists from around the world to obtain X-ray images of exotic environments to help understand the structure and evolution of the universe.

\todo[inline]{To be completed: CXC; catalog, data... and VO access.}


\subsubsection{XMM-Newton}

The European Space Agency's (ESA) X-ray Multi-Mirror Mission (XMM-Newton) was launched in 1999. XMM-Newton is ESA's second cornerstone of the Horizon 2000 Science Program. It carries 3 high throughput X-ray telescopes with an unprecedented effective area, and an optical monitor, dedicated to the study of celestial X-ray sources.

\todo[inline]{To be completed: XMM catalogs, data... and VO access.}


\subsubsection{SVOM}

The SVOM mission (Space-based multi-band astronomical Variable Objects Monitor) is a Franco-Chinese mission dedicated to the study of the most distant explosions of stars, the gamma-ray bursts. It is to be launched end 2023.

\todo[inline]{To be completed}



\subsection{KM3Net and neutrino detection}

The KM3NeT neutrino detectors are an array of water-based Cherenkov detectors currently under construction in the deep Mediterranean Sea. With its two sites off the French and Italian coasts the KM3NeT collaboration aims at single particle neutrino detection for neutrino physics with the more densely instrumented ORCA detector in the GeV to TeV range, and high-energy astrophysics with the ARCA detector in the TeV range and above.

Using Earth as a shield from atmospheric particle interference by searching for upgoing particle tracks in the detectors, the measurement of astrophysical neutrinos can be performed almost continuously for a wide field of view that covers the full visible sky. For these particle events, extensive Monte Carlo simulations are performed to evaluate the statistical significance towards the various theoretical assumptions for galactic or cosmic neutrino signals.

During the construction phase, the KM3NeT collaboration develops its interfaces for open science and builds on the data gathered by its predecessor ANTARES, from which neutrino event lists have already been published on the KM3NeT VO server as TAP service. However, reproducibility of the searches for point-like sources require information derived from simulations like background estimate, point spread function and detector acceptance which require linking to the actual event list and interpretation for a given observation, usually as neutrino flux limits for non-significant detection attributable to background rather than an observation.

With multiple detectors targeting high-energy neutrinos like IceCube, ANTARES, KM3NeT, Baikal and future projects, the chance to detect a significant amount of cosmic and galactic neutrinos increases, requiring an integrated approach to link event lists with instrument responses and to correctly interpret observation time and flux expectations.


\todo[inline]{To be completed (e.g. Jutta) - information was added by Jutta}


%\subsection{Gravitational wave detection}



% mireille : what is specific for the community in terms of data interpretation and computation steps

\section{Common practices in the High Energy community}

\subsection{Data flow specificities}

\subsubsection{Event-counting}

Observations of the Universe at high energies are based on techniques that are radically different compared to the optical, or radio domain. HE observatories are generally designed to detect particles, e.g. individual photons, cosmic-rays, or neutrinos, with the ability to estimate several characteristics of those particles. This technique is generally named \textbf{event counting}, where an event has some probability of being due to the interaction of an astronomical particle with the detectors.

The data corresponding to an \textbf{event} is first an instrumental signal, which is then calibrated and processed to estimate event characteristics such as a time of arrival, coordinates on the sky, and the energy proxy associated to the event. Several other intermediate and qualifying characteristics can be associated to a detected event.

When observing during an interval of time, the data collected is a list of the detected events, named an \textbf{event list} in the HE domain, and event-list in this document.

%HE projects already have data formats in use to transport the results of observations together with the necessary instrument response files.

%Such response files depend on the way raw event lists are combined together; they are essential for the calibration steps that will help to produce calibrated event-lists in position, time and energy.


\subsubsection{Data levels}

After the detection of events, data processing steps are applied to generate data products corresponding at least 3 data levels.
For example, in the VHE Cherenkov astronomy domain (e.g. CTA), those data levels are labelled DL3\footnote{events being reconstructed, lower level data is specific this domain (DL0-DL2).} to DL5. In the X-ray domain, this would correspond to L1, L2, L3.

\begin{itemize}
    \item L1 (or DL3): an event-list is first a list of events with calibrated temporal and spatial characteristics (e.g. sky coordinates for a given epoch, time with a reference)
    \item L2 (or DL4): the event-list is then binned to generate images, spectra of light-curve in counts unit, and corresponding instrument response correction (exposure maps, sensitivity maps...)
    \item L3 (or DL5): Calibrated maps, or spectral energy distributions for a source, or light-curves in physical units
\end{itemize}

An additional data level corresponds to catalogs, e.g. a source catalog pointing to several data products, each one corresponding to a source.


\subsubsection{Background signal}

Observations in HE may contain a high background signal, that may be due to instrument noises, or to unresolved astrophysical sources, emission from extended regions or other terrestrial sources producing particles similar to the signal. The characterization and estimation of this background is particularly important to then apply corrections during the analysis of a source signal.


\subsubsection{Time intervals}

Depending on the stability of the instruments and observing conditions, a HE observation can be decomposed into several intervals of time that will be further analysed.
For example, Stable Time Intervals (STI) are defined in Cherenkov astronomy to characterize the instrument response over a stable period of time. In the X-ray domain, Good Time Intervals (GTI) are computed, e.g. to reject intervals of time contaminated by solar flares. In contrast, for neutrino physics, relevant observation periods can cover up to several years due to the low statistics of the expected signal and a continuous observational coverage of the full field of view.


\subsubsection{Instrument Response Functions}

Though an event-list can contain calibrated physical values, this data still have to be corrected for the response of the instruments used. Several {Instrument Response Functions (IRFs)} thus have to be applied to enable a scientific analysis of an event-list. The IRFs are applied to convert the events that were detected into an estimation of the real flux of particles arriving at the instrument and morphology of the source.

\subsubsection{Granularity of data products}

The efficient granularity for distributing HE data products seems to be the full combination of data and IRFs, although some of the IRFs may also be recomputed by a service or script after parameters selection.

In order to allow for multi-wavelength data discovery of HE data products and compare observations across different regimes, it seems appropriate to distribute the metadata in the VO ecosystem together with an access link to the data file in community format for finer analysis.

% mir already mentionned above why we should consider IRF
%The coverage information, i.e. how the data product spans on the sky coordinates, and along time and energy axis, is an important criterium for data selection. In the case of HE observations, these parameters vary depending on the selected good time intervals.
% to be developed

The event-list dataset is generally stored as a table, with one row for a candidate detection (event) and several columns for the estimated physical parameters, at least time, sky position, energy, and extra parameters not standardized across projects: errors, flags, etc.

The list of columns present in the event-list is for example described in the data format in use in the HE domain, such as OGIP or GADF as introduced below. The data formats in use generally describe the event-list data together with the IRFs and other relevant information, such as: Stable or Good Time Interval, Effective Area, Energy Dispersion, Point Spread Function, Background,...

%From an observation file, the event data can lead to several data products results, depending on the parameter selections induced from the knowledge of the IRF.


\subsection{Work flow specificities}

\subsubsection{Event selection}

When processing an event-list, it is important to perform an optimal {selection of the events} that are more likely to be due to the incident particles expected. This selection may depend on the source targeted or on the science objectives.

\subsubsection{Assumptions and probabilistic approach}

In order to produce advanced data products like light curves or spectra, {assumptions} about the kind of particles, noise, source type and its expected energy distribution must be introduced. This is one of the main driver for enabling a full and well described access to event-list data, as scientific analyses generally start at this data level.


\subsection{Data formats}
\label{sec:data_formats}

\subsubsection{{OGIP}}

The HEASARC FITS Working Group, also known as the OGIP (Office of Guest Investigator Programs) FITS Working Group, has promoted multi-mission standards for the format of FITS data files in high-energy astrophysics. Those recommendations\footnote{\url{https://heasarc.gsfc.nasa.gov/docs/heasarc/ofwg/ofwg_recomm.html}} include standards on keyword usage in metadata, on storage of time information, and representation of response function.

\todo[inline]{To be completed}


\subsubsection{GADF and VODF}
\label{sec:GADF}

The data formats for gamma-ray astronomy\footnote{\url{https://gamma-astro-data-formats.readthedocs.io/}} (GADF) is a community-driven initiative for the definition of a common and open high-level data format for gamma-ray instruments \citep{2021-DF}. GADF is based on the OGIP standards and is specialised for Very High Energy data.

The Very-high-energy Open Data Format\footnote{\url{https://vodf.readthedocs.io/}} (VODF), is an open data model and format for Very-High-Energy (VHE) gamma-ray and neutrino astronomy. Its goal is to provide a standard set of file formats and standards for data starting at the reconstructed event level as well as higher-level products such as N-dimensional binned data cubes (including sky images, light curves, and spectra) and source catalogues. With these standards, common science tools can be used to analyze data from multiple high-energy instruments. VODF aims to follow as much as possible the IVOA standards.

\todo[inline]{To be completed}

\subsection{Tools for data extraction and visualisation}
Xray data are analysed by general tools like Xspec, gammapy, and ... TBC .
Some tools are specific to the data archive like CiaO for Chandra, for instance.
\todo[inline]{To be completed (e.g. ???)}

% mireille : to be discussed
%??? naïve question : what would be the benefit to convert science ready event table data to VOTable?
%Would TOPcat, Aladin, etc. allow more preview steps  , xmatch, multi-wavelength analysis ?

\section{Use Cases}

\subsection{UC1: re-analyse event-list data for a source in a catalog}

After the selection of a source of interest, or a group of sources, one may access different HE data products such as images, spectra and light-curves, and then want to download the corresponding event-lists and calibrations to further analyse the data.

\todo[inline]{To be completed (e.g. Paula, Laurent)}
One of the characteristics of the HE data is that, contrary to what is usually done in optics for example, their optimal use requires providing users with a view of the processing that generated the data. This implies providing ancillary data, products with different calibration levels, and possibly linking together products issued by the same processing.  (LM)


\subsection{UC2: observation preparation}

When planning for a new HE observation, one needs to search for any existing event-list data already available in the targeted sky regions, and assess if this data is sufficient to fulfill the science objectives.

\todo[inline]{To be completed (e.g. Bruno)}


\subsection{UC3: transient or variable sources}


\todo[inline]{To be completed (e.g. Ada)}


\subsection{UC4: Multi-wavelength and multi-messenger science}

Though there are scientific results based on HE data only, the multi-wavelength and multi-messenger approach is particularly developed in the HE domain. An astrophysical source of HE radiations is indeed generally radiating energy in several domains across the electromagnetic spectrum and may be a strong source of other particles. It is not rare to observe a HE source in radio and to look for counterparts in the infrared, optical or UV domain. Spectroscopy is also widely used to identify HE sources.

The HE domain is thus confronted to different kinds of data types and data archives, which leads to interesting use cases for the development of the VO.

\todo[inline]{To be completed (e.g. Bruno)}


\subsection{Examples of multi-wavelength analysis}

\subsubsection{Multiple Imaging Atmospheric Cherenkov Telescopes extraction example}

In order to exploit high energy data across a large interval of energy values, and from various IACTs, there is a need to harmonise metadata description.
Datasets can then be mixed together to create a fused event-list dataset, to expand the analysis along the spectral energy axis and study the spectral behaviour of an astronomical object.

This was proposed in \citep{2019A&A...625A..10N} by a group of HE astronomers of various HE facilities.
%This work used event-list data products as an input from different facilities (MAGIC, H.E.S.S., FACT, VERITAS, etc...).  data for the Crab Nebula computed from the Maximum likelihood functions of each event depending on the IRFs properties.
In this work, the authors implemented a prototypical data format (GADF) for a small set of MAGIC, VERITAS, FACT, and H.E.S.S. Crab nebula observations, and they analyzed them with the open-source gammapy software package. By combining data from Fermi-LAT, and from four of the currently operating imaging atmospheric Cherenkov telescopes, they produced a joint maximum likelihood fit of the Crab nebula spectrum.

Such a work has been more recently extended with the HAWC data \citep{2022A&A...667A..36A}, and included neutrino data in a common CTA and KM3NeT source search \citep{unbehaun2023prospects}.


\section{IVOA standards of interest for HE}

\subsection{IVOA Recommendations}

\subsubsection{ObsCore and TAP}

Event-list datasets can be described in ObsCore using a dataproduct\_type set to "event". However, this is not widely used in current services, and we observe only a few services with event-list datasets declared in the VO Registry, and mainly the H.E.S.S. public data release (see \ref{sec:hess}).

As services based on the Table Access Protocol \citep{2019ivoa.spec.0927D} and ObsCore are well developed within the VO, it would be a straightforward option to discover HE event-list datasets, as well as multi-wavelength and multi-messenger associated data.

Here is the evaluation of the ObsCore metadata for distributing high energy data set, some features being re-usable as such, and some other features requested for addition or re-interpretation.


\subsubsection{DataLink}

%\todo[inline]{To be completed (e.g. François)} proposed below by FB (2024-01-31)

DataLink specification \citep{2023ivoa.spec.1215B} defines a \{links\} endpoint providing the possibility to link several
access items to each row of the main response table. These links are described and stored in a second
table. In the case of an ObsCore response each dataset can be linked this way (via the via the access\_url
FIELD content) to previews, documentation pages, calibration data as well as to the dataset itself.
Some dynamical links to web services may also be provided. In that case the service input parameters are
described with the help of a "service descriptor" feature as described in the same DataLink specification.

\subsubsection{HiPS}

Several HE observatories are well suited for sky survey, and the Hierarchical Progressive Survey (HiPS) standard is well suited for sky survey exploration. We note that the Fermi facility provides a useful sky survey in the GeV domain.


\subsubsection{MOCs}

Cross-correlation of data with other observations is an important use case in the HE domain. Using the Multi-Order Coverage map (MOC) standard, such operations become more efficient. Distribution of MOCs associated to HE data should thus be encouraged and especially ST-MOCs (space + time coverage)
that make easier the study of transient phenomena.
% (LM)

\subsubsection{MIVOT}

Model Instances in VOTables (MIVOT) defines a syntax to map VOTable data to any model serialized in VO-DML. The annotation operates as a bridge between the data and the model. It associates the column/param metadata from the VOTable to the data model elements (class, attributes, types, etc.) [...]. The data model elements are grouped in an independent annotation block complying with the MIVOT XML syntax. This annotation block is added as an extra resource element at the top of the VOTable result resource. The MIVOT syntax allows to describe a data structure as a hierarchy of classes. It is also able to represent relations and composition between them. It can also build up data model objects by aggregating instances from different tables of the VOTable.
In the case of HE data, this annotation pattern, used together with the MANGO model, will help to make machine-readable quantities that are currently not considered in the VO, such as the hardness ratio, the energy bands, the flags associated with measurements or  extended sources.
% (LM)

\todo[inline]{To be completed}



\subsubsection{Provenance}

\todo[inline]{To be completed (e.g. Mathieu)}


\subsection{Data Models in working drafts}

The HE domain and practices could serve as use cases for the developments of data models, such as Dataset DM, Cube DM or MANGO DM.


\section{Topics for discussions in an Interest Group}


\subsection{Definition of a HE event in the VO}

The IVOA standards incude the concept of event-list, for example in ObsCore v1.1 \citep{2017ivoa.spec.0509L}, where event is a dataproduct\_type with the following definition:
\begin{quote}
    \textbf{event}: an event-counting (e.g. X-ray or other high energy) dataset of some sort. Typically this is instrumental data, i.e., "event data". An event dataset is often a complex object containing multiple files or other substructures. An event dataset may contain data with spatial, spectral, and time information for each measured event, although the spectral resolution (energy) is sometimes limited. Event data may be used to produce higher level data products such as images or spectra.
\end{quote}

More recently, a new definition was proposed in the product-type vocabulary\footnote{\url{https://www.ivoa.net/rdf/product-type}} (draft):
\begin{quote}
    \textbf{event-list}: a collection of observed events, such as incoming high-energy particles. A row in an event list is typically characterised by a spatial position, a time and an energy.
\end{quote}

Such a definition remains vague and general, and could be more specific, including a definition for a HE event, and the event-list data type.

\paragraph{Discussion topics:}
\begin{itemize}
    \item Propose definitions for product-type:
    \begin{itemize}
        \item \textbf{event-list}: A collection of observed events, such as incoming high-energy particles, where an event is generally characterised by a spatial position, a time and a spectral value (e.g. an energy or a channel).
        \item \textbf{event-bundle}: An event-bundle dataset is a complex object containing an event-list and multiple files or other substructures with contextual information, in order to correct from the instrument signature in the detection of events. Event-bundle data may be used to produce higher level data products such as images or spectra.
    \end{itemize}

    \item ObsCore erratum: change event for event-list and event-bundle

\end{itemize}


\subsection{ObsCore metadata description of an event-list}
%%%% texte by Mireille to be checked and merged : start %%
%\include{ObscoreReviewforVOHEcontext_Mireille Louys}
%I have some items to add in the various categories well defined by Mathieu
%%%%%%%%%%texte by Mireille to be merged : end %%

%\subsubsection{Mandatory fields}

\subsubsection{Usage of the mandatory terms in ivoa.Obscore}

ObsCore \citep{2017ivoa.spec.0509L} can provide a metadata profile for a data product of type event-list and a qualified access to the distributed file using the Access class from ObsCore (URL, format, file size).

In the ObsCore representation, the event-list data product is described in terms of curation, coverage and access. However, several properties are simply set to NULL following the recommendation: Resolutions, Polarization States, Observable Axis Description, Axes lengths (set to -1)...

We also note that some properties are energy dependent, such as the Spatial Coverage, Spatial Extent.

\todo[inline]{TODO: show a table with all reused terms , and provide an example}

\begin{itemize}
    \item dataproduct\_subtype = DL3, maybe specific data format (VODF)
    \item calib\_level = between 1 and 2
    \item obs\_collection could contain many details : obs\_type (calib, science), obs\_mode (subarray
configuration), pointing\_mode, tracking\_mode, event\_type, event\_cuts, analysis\_type…
    \item s\_ra, s\_dec = telescope pointing coordinates
    \item target\_name : several targets may be in the field of view
    \item s\_fov, s\_region, s\_resolution, em\_resolution… all those values are energy dependent, one should specifiy that the value is at a given energy, or within a range of values.
    \item em\_min, em\_max : add fields expressed in energy (e.g. TeV)
    \item t\_exptime : ontime, livetime, stable time intervals… maybe a T-MOC would help
    \item facility\_name, instrument\_name : minimalist, would be e.g. CTAO and a subarray.
\end{itemize}



\subsubsection{Metadata re-interpretation for the VOHE context}

\paragraph{observation\_id}
In the current definition of ObsCore DM, the data product collects data from one or several observations.
The same happens in HE context.

\paragraph{access\_ref, access\_format}
The initial role of this metadata was to hold the access\_url allowing data access.
Depending on the packaging of the event bundle in one compact format (OGIP, GADF, tar ball, ...)
or as different files available independently in various urls, a datalink pointer can be
used for accessing the various parts of IRFs, background maps, etc.
Then in such a case the value for access\_format should be "application/x-votable+xml;content=datalink".
The format itself of the data file is then given by the datalink parameter "content-type".
See next section \ref{sec:datalink}.

\paragraph{o\_ucd}
For the evenlist table, we can consider all measures stored in columns values have been observed .
The nature of items along time, position and energy axis are identifed in Obscore with ucd as 'time', 'pos.eq.*', 'em.*'
and counted as t\_xel, s\_xel1, s\_xel2, em\_xel which correspond to the number of rows/events candidates observed.

The signal observed is the result of event counting and would be PHA (Pulse height amplitude at detector level)
or a number of counts for photons or particles, or a flux, etc.., depending on the data calibration level considered.
ObsCore uses o\_ucd to characterise the nature of the measure.
various UCDs are used for that :
o\_ucd=phys.count, phot.count, phot.flux, etc..
there is currently no ucd defined for a raw measure like PulseHeightAmplitude,
but if needed this can be requested for addition in the UCDList vocabulary .
see VEP-UCD-15\_pulseheight.txt proposed at
\url{'https://voparis-gitlab.obspm.fr/vespa/ivoa-standards/semantics/vep-ucd/-/blob/master/'}.

Note that these parameters vary between the dataset of calib\_level of 1 (Raw) to the a more advanced data products (calib\_level 2 or 3), which are  filtered and rebinned from the original raw event-list.



\subsubsection{Metadata addition required}

\paragraph{ev\_number}
The event list contains a number of rows, representing detections candidates, that have no metadata keyword yet in Obscore.
We propose 'ev\_number' to record this.
In fact the t\_xel, s\_xel1 and s\_xel2, em\_xel elements do not apply for an event list in raw count
as it has not been binned yet.

\paragraph{Adding MIME-type to access\_format table}
As seen in section \ref{sec:data_formats} current HE experiments and observatories
use their community defined data format for data dissemination.
They encapsulate the event-list table together with ancillary data dedicated
to calibration and observing configurations and parameters.
Even if the encapsulation is not standardized between the various projects,
it is useful for a client application to rely on the access\_format property in
order to send it to an appropriate visualizing tool.

Therefore these can be included in the MIME-type table of ObsCore section 4.7.
suggestion for new terms like :
\begin{itemize}
\item application/x-fits-ogip ...
\item application/x-gadf  ...
\item application/x-vodf  ...
\end{itemize}
\todo[inline]{to be completed with proper definition}

\paragraph{energy\_min, energy\_max}
It is not user-friendly for the user to select dataset according to an energy range
when the spectral axis is expressed in wavelength and meters. The units and quantities are not familiar to this community.
Moreover the numerical representation of the spectral range in em\_min leads to quantities with many figures and a power as -18 not easily comparable with the current usage.

\todo[inline]{cf. example HESS data shown in Aladin}



\paragraph{t\_min, t\_max}

The searching criteria in terms of time coverage require the list of stable/good time intervals to pick appropriate datasets.
t\_min, t\_max is the global time span but t\_gti could contain the list of GTI as a T\_MOC description following the Multi-Order-Coverage (MOC) IVOA standard \citep{2022ivoa.spec.0727F}.
This element could then be compared across data collections to make the data set selection via simple intersection or union operations in T\_MOC representation.
On the data provider's side, the T-MOC element can be computed from the Stable/Good Time Interval table in OGIP or GADF to produce the ObsCore t\_gti field.




\subsubsection{Access and Description of IRFs}

Each IRF file can have an Access object from ObsCore DM to describe a link to the IRF part of the data file.
This can be reflected in an extension of ObsTAP TAP\_SCHEMA.

In the TAP service we can add an IRF Table, with the following columns:

\begin{itemize}
    \item event-list datapublisher\_id
    \item irf\_type, category of response: EffectiveArea, PSF, etc.
    \item irf\_description, one line explanation for the role of the file
    \item Access.url, URL to point to the IRF
    \item Access.format, format of IRF
    \item Access.size, size of IRF file
\end{itemize}



\subsection{Event-list Context Data Model}
\label{sec:EventListContext}

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figures/EventListContext}
\caption{event-list Context Data Model}
\label{fig:EventListContext}
\end{figure}

The event-list concept may include, or may be surrounded by other connected concepts. Indeed, an event-list dataset alone cannot be scientifically analysed without the knowledge of some contextual data and metadata, starting with the good/stable time intervals, and the corresponding IRFs.

The aim of the Event-list Context Data Model is to name and indicate the relations between the event-list and its contextual information. It is presented in Figure~\ref{fig:EventListContext}.


\subsection{Use of Datalink for HE products}
\label{sec:datalink}
There are two options to provide an access to a full event-list package.

First, the event-list dataset itself can contain all the relevant information, e.g. several frames in FITS file, one corresponding to the event-list itself, and the other providing good/stable time intervals, or any IRF file. This is what was done in the current GADF data format (see \ref{sec:GADF}).

The second option is to provide links to the relevant information from the base event-list dataset. This could be done using Datalink and a list of link to each contextual information such as the IRFs. The Event-list Context Data Model (see \ref{sec:EventListContext}) would provide the concepts and vocabulary to characterise the IRFs and other information relevant to the analysis of an event-list.

In the first option, The content of the event-list package should be properly defined in its description: what information is included and where is it in the dataset structure? HEre again, the Event-list Context Data Model (see \ref{sec:EventListContext}) would be useful.


\todo[inline]{To be completed}




\bibliography{VOHE-Note, ivoatex/docrepo, ivoatex/ivoabib}
%\bibliographystyle{}

\appendix

\section{Changes from Previous Versions}

No previous versions yet.
% these would be subsections "Changes from v. WD-..."
% Use itemize environments.


% NOTE: IVOA recommendations must be cited from docrepo rather than ivoabib
% (REC entries there are for legacy documents only)

\end{document}
